{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCAACAADD\n",
      "['A', 'B', 'C', 'D']\n",
      "     A    B    C    D\n",
      "A  0.1    0  0.3  0.6\n",
      "B  0.5  0.4  0.1    0\n",
      "C  0.3  0.3  0.3  0.1\n",
      "D  0.2  0.5  0.1  0.2\n"
     ]
    }
   ],
   "source": [
    "def text_to_input(lines):\n",
    "    pi_input = lines[0].strip()\n",
    "\n",
    "    states_input = [line.strip() for line in lines[2].split()]\n",
    "    \n",
    "    trans_matrix = []\n",
    "    for line in lines[5:]:\n",
    "        trans_matrix.append(line.strip().split()[1:])\n",
    "\n",
    "    trans_df_input = pd.DataFrame(trans_matrix, columns=states_input, index=states_input)\n",
    "\n",
    "    return pi_input, states_input, trans_df_input\n",
    "\n",
    "with open('01_ProbabilityHMMPath/inputs/test4.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "pi_input, states_input, trans_df_input = text_to_input(lines)\n",
    "print(pi_input)\n",
    "print(states_input)\n",
    "print(trans_df_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.100000000000001e-07\n"
     ]
    }
   ],
   "source": [
    "def prob_hidden_path(pi: str, states: List[str], trans_df: pd.DataFrame):\n",
    "    probability = float(1/len(states))\n",
    "    for i in range(len(pi)):\n",
    "        curr_symbol = pi[i]\n",
    "        if i != len(pi)-1:\n",
    "            next_symbol = pi[i+1]\n",
    "            added_prob = float(trans_df.loc[curr_symbol, next_symbol])\n",
    "            probability = probability * added_prob\n",
    "    return probability\n",
    "\n",
    "print(prob_hidden_path(pi_input, states_input, trans_df_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zxzzyyzxzzxxxzyzzyyxzyxxxxyxyxzyyxzyxyxzzyzzxyzyyx\n",
      "['x', 'y', 'z']\n",
      "ABBABBBBABBABBBABBAABBBAABABBBABAAABAABBBBBBABAABA\n",
      "['A', 'B']\n",
      "       x      y      z\n",
      "A  0.274  0.145  0.581\n",
      "B  0.109  0.254  0.637\n"
     ]
    }
   ],
   "source": [
    "def given_hidden_path_inputs(lines):\n",
    "    x_input = lines[0].strip()\n",
    "\n",
    "    alphabet_input = [line.strip() for line in lines[2].split()]\n",
    "    \n",
    "    pi_input = lines[4].strip()\n",
    "\n",
    "    states_input = [line.strip() for line in lines[6].split()]\n",
    "\n",
    "    emissions_matrix = []\n",
    "    for line in lines[9:]:\n",
    "        emissions_matrix.append(line.strip().split()[1:])\n",
    "\n",
    "    emissions_df_input = pd.DataFrame(emissions_matrix, columns=alphabet_input, index=states_input)\n",
    "\n",
    "    return x_input, alphabet_input, pi_input, states_input, emissions_df_input\n",
    "\n",
    "with open('dataset_40267_10.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "x_input, alphabet_input, pi_input, states_input, emissions_df_input = given_hidden_path_inputs(lines)\n",
    "print(x_input)\n",
    "print(alphabet_input)\n",
    "print(pi_input)\n",
    "print(states_input)\n",
    "print(emissions_df_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0866055169952337e-28\n"
     ]
    }
   ],
   "source": [
    "def prob_outcome_given_hidden_path(x:str, pi: str, emissions_df: pd.DataFrame):\n",
    "    probability = 1\n",
    "    for i in range(len(pi)):\n",
    "        curr_pi = pi[i]\n",
    "        curr_x = x[i]\n",
    "        added_prob = float(emissions_df.loc[curr_pi, curr_x])\n",
    "        probability = probability * added_prob\n",
    "    return probability\n",
    "\n",
    "print(prob_outcome_given_hidden_path(x_input, pi_input, emissions_df_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xzyyz\n",
      "['x', 'y', 'z']\n",
      "['A', 'B']\n",
      "       A      B\n",
      "A  0.303  0.697\n",
      "B  0.831  0.169\n",
      "       x      y      z\n",
      "A  0.533  0.065  0.402\n",
      "B  0.342  0.334  0.324\n"
     ]
    }
   ],
   "source": [
    "def viterbi_path_inputs(lines):\n",
    "    x_input = lines[0].strip()\n",
    "\n",
    "    alphabet_input = [line.strip() for line in lines[2].split()]\n",
    "\n",
    "    states_input = [line.strip() for line in lines[4].split()]\n",
    "\n",
    "    trans_matrix = []\n",
    "    trans_matrix_start = 7\n",
    "    for line in lines[trans_matrix_start:trans_matrix_start + len(states_input)]:\n",
    "        trans_matrix.append(line.strip().split()[1:])\n",
    "\n",
    "    trans_df_input = pd.DataFrame(trans_matrix, columns=states_input, index=states_input).astype(float)\n",
    "\n",
    "    emissions_matrix = []\n",
    "    emissions_start = trans_matrix_start + len(states_input) + 2\n",
    "    for line in lines[emissions_start:emissions_start + len(states_input)]:\n",
    "        emissions_matrix.append(line.strip().split()[1:])\n",
    "\n",
    "    emissions_df_input = pd.DataFrame(emissions_matrix, columns=alphabet_input, index=states_input).astype(float)\n",
    "\n",
    "    return x_input, alphabet_input, states_input, trans_df_input, emissions_df_input\n",
    "\n",
    "with open('04_OutcomeLikelihood/inputs/sample.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "x_input, alphabet_input, states_input, trans_df_input, emissions_df_input = viterbi_path_inputs(lines)\n",
    "print(x_input)\n",
    "print(alphabet_input)\n",
    "print(states_input)\n",
    "print(trans_df_input)\n",
    "print(emissions_df_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBCAAAAAAACBCBCAAAAACBCAAAAAAAAAAAAAAAAAAAAAAAAACBCAAAAAAAAAAAAAAAAAAAACBCAAAAAAAAAAACBCBCACBCAAAAAA\n"
     ]
    }
   ],
   "source": [
    "def viterbi_algorithm(x: str, alphabet: List[str], states: List[str],\n",
    "                      trans_df: pd.DataFrame, emissions_df: pd.DataFrame):\n",
    "    pi = ''\n",
    "    backtrack_df = pd.DataFrame(1, index=states, columns=list(x)).astype(object)\n",
    "    viterbi_graph = {state: [0] * len(x) for state in states}\n",
    "    for j in range(len(x)):\n",
    "        for curr_state in states:\n",
    "            prob_emission_given_state = emissions_df.loc[curr_state, x[j]]\n",
    "            if j == 0:\n",
    "                viterbi_graph[curr_state][j] = prob_hidden_path(pi, states, trans_df) * prob_emission_given_state\n",
    "                backtrack_df.loc[curr_state, x[j]] = 'S'\n",
    "            else:\n",
    "                max_prob = 0.0\n",
    "                max_prev_state = states[0]\n",
    "                for prev_state in states:\n",
    "                    prob_trans = trans_df.loc[prev_state, curr_state]\n",
    "                    current_prob = viterbi_graph[prev_state][j - 1] * prob_trans * prob_emission_given_state\n",
    "                    if current_prob > max_prob:\n",
    "                        max_prob = current_prob\n",
    "                        max_prev_state = prev_state\n",
    "                viterbi_graph[curr_state][j] = max_prob\n",
    "                backtrack_df.iloc[states.index(curr_state), j] = max_prev_state\n",
    "    max_prob = 0\n",
    "    most_probable_state = states[0]\n",
    "    for state in states:\n",
    "        if viterbi_graph[state][-1] > max_prob:\n",
    "            max_prob = viterbi_graph[state][-1]\n",
    "            most_probable_state = state\n",
    "    pi = most_probable_state + pi\n",
    "\n",
    "    current_state = most_probable_state\n",
    "    for i in range(len(x)-1, 0, -1):\n",
    "        prev_state = backtrack_df.iloc[states.index(current_state), i]\n",
    "        pi = prev_state + pi\n",
    "        current_state = prev_state\n",
    "    return pi\n",
    "print(viterbi_algorithm(x_input, alphabet_input, states_input, trans_df_input, emissions_df_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxyzxxxzxyxzzyzyyyxzxyyzxyxzzzyxxxxyxzzxxzzyxzzzyzxzyzzyxxzyzxyyzxxzxzxzzyxzyzxzxxxxxxyzxzxyyyzxzxyx\n",
      "['x', 'y', 'z']\n",
      "['A', 'B', 'C', 'D']\n",
      "       A      B      C      D\n",
      "A  0.155  0.364  0.102  0.379\n",
      "B  0.426  0.190  0.050  0.334\n",
      "C  0.354  0.032  0.329  0.285\n",
      "D  0.372  0.343  0.029  0.256\n",
      "       x      y      z\n",
      "A  0.046  0.498  0.456\n",
      "B  0.062  0.496  0.442\n",
      "C  0.412  0.202  0.386\n",
      "D  0.223  0.540  0.237\n"
     ]
    }
   ],
   "source": [
    "def outcome_likelihood_inputs(lines):\n",
    "    x_input = lines[0].strip()\n",
    "\n",
    "    alphabet_input = [line.strip() for line in lines[2].split()]\n",
    "\n",
    "    states_input = [line.strip() for line in lines[4].split()]\n",
    "\n",
    "    trans_matrix = []\n",
    "    trans_matrix_start = 7\n",
    "    for line in lines[trans_matrix_start:trans_matrix_start + len(states_input)]:\n",
    "        trans_matrix.append(line.strip().split()[1:])\n",
    "\n",
    "    trans_df_input = pd.DataFrame(trans_matrix, columns=states_input, index=states_input).astype(float)\n",
    "\n",
    "    emissions_matrix = []\n",
    "    emissions_start = trans_matrix_start + len(states_input) + 2\n",
    "    for line in lines[emissions_start:emissions_start + len(states_input)]:\n",
    "        emissions_matrix.append(line.strip().split()[1:])\n",
    "\n",
    "    emissions_df_input = pd.DataFrame(emissions_matrix, columns=alphabet_input, index=states_input).astype(float)\n",
    "\n",
    "    return x_input, alphabet_input, states_input, trans_df_input, emissions_df_input\n",
    "\n",
    "with open('dataset_40269_4.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "x_input, alphabet_input, states_input, trans_df_input, emissions_df_input = viterbi_path_inputs(lines)\n",
    "print(x_input)\n",
    "print(alphabet_input)\n",
    "print(states_input)\n",
    "print(trans_df_input)\n",
    "print(emissions_df_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.405857847247358e-57\n"
     ]
    }
   ],
   "source": [
    "def outcome_likelihood(x: str, alphabet: List[str], states: List[str],\n",
    "                      trans_df: pd.DataFrame, emissions_df: pd.DataFrame):\n",
    "    graph = {state: [0] * len(x) for state in states}\n",
    "    for j in range(len(x)):\n",
    "        for curr_state in states:\n",
    "            prob_emission_given_state = emissions_df.loc[curr_state, x[j]]\n",
    "            if j == 0:\n",
    "                graph[curr_state][j] = 1/len(states) * prob_emission_given_state\n",
    "            else:\n",
    "                total_prob = 0.0\n",
    "                for prev_state in states:\n",
    "                    prob_trans = trans_df.loc[prev_state, curr_state]\n",
    "                    current_prob = graph[prev_state][j - 1] * prob_trans * prob_emission_given_state\n",
    "                    total_prob += current_prob\n",
    "                graph[curr_state][j] = total_prob\n",
    "    \n",
    "    outcome_likelihood = 0\n",
    "    for state in states:\n",
    "        state_likelihood = graph[state][-1]\n",
    "        outcome_likelihood += state_likelihood\n",
    "    \n",
    "    return outcome_likelihood\n",
    "print(outcome_likelihood(x_input, alphabet_input, states_input, trans_df_input, emissions_df_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.322\n",
      "['A', 'B', 'C', 'D', 'E']\n",
      "['-CBD-BC-D', 'DCCD-BAE-', 'EACCEBBED', 'ECC-EBDED', 'EEBDE-BED', 'ECCDEEBED']\n"
     ]
    }
   ],
   "source": [
    "def profile_hmm_inputs(lines):\n",
    "    threshold_input = lines[0].strip()\n",
    "\n",
    "    alphabet_input = [line.strip() for line in lines[2].split()]\n",
    "\n",
    "    alignment_input = [line.strip() for line in lines[4:]]\n",
    "\n",
    "    return float(threshold_input), alphabet_input, alignment_input\n",
    "\n",
    "with open('dataset_40270_15.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "threshold_input, alphabet_input, alignment_input = profile_hmm_inputs(lines)\n",
    "print(threshold_input)\n",
    "print(alphabet_input)\n",
    "print(alignment_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_graph(alignment, alphabet, hmm_list, trans_matrix, emissions_matrix, seq_pos):\n",
    "    transition_counts = {state: {target: 0 for target in hmm_list} for state in hmm_list}\n",
    "    emission_counts = {state: {letter: 0 for letter in alphabet} for state in hmm_list}\n",
    "\n",
    "    for sequence in alignment:\n",
    "        prev_state = 'S'\n",
    "        match_index = 0\n",
    "        for i in range(len(seq_pos)):\n",
    "            is_match = seq_pos[i][1]\n",
    "            if is_match:\n",
    "                match_index += 1\n",
    "                state = f'D{match_index}' if sequence[i] == '-' else f'M{match_index}'\n",
    "            else:\n",
    "                state = f'I{match_index}' if sequence[i] != '-' else None\n",
    "\n",
    "            if state:\n",
    "                if state in hmm_list:\n",
    "                    if state.startswith('M') or state.startswith('I'):\n",
    "                        if sequence[i] in alphabet:\n",
    "                            emission_counts[state][sequence[i]] += 1\n",
    "                    transition_counts[prev_state][state] += 1\n",
    "                    prev_state = state\n",
    "\n",
    "        transition_counts[prev_state]['E'] += 1\n",
    "\n",
    "    for state in hmm_list:\n",
    "        total_transitions = sum(transition_counts[state].values())\n",
    "        if total_transitions > 0:\n",
    "            for target in hmm_list:\n",
    "                trans_matrix.at[state, target] = transition_counts[state][target] / total_transitions\n",
    "\n",
    "    for state in hmm_list:\n",
    "        total_emissions = sum(emission_counts[state].values())\n",
    "        if total_emissions > 0:\n",
    "            for letter in alphabet:\n",
    "                emissions_matrix.at[state, letter] = emission_counts[state][letter] / total_emissions\n",
    "\n",
    "    return trans_matrix, emissions_matrix\n",
    "\n",
    "\n",
    "def profile_hmm(threshold: float, alphabet: List[str], alignment: List[str]):\n",
    "    seq_pos = []\n",
    "    for i in range(len(alignment[0])):\n",
    "        pos = [seq[i] for seq in alignment]\n",
    "        num_dels = sum(1 for letter in pos if letter == '-')\n",
    "        seq_pos.append((pos, num_dels / len(pos) < threshold))\n",
    "\n",
    "    alignment_star = [pos[0] for pos in seq_pos if pos[1]]\n",
    "\n",
    "    hmm_length = len(alignment_star)\n",
    "    hmm_list = ['S', 'I0'] + [f'{state}{i}' for i in range(1, hmm_length + 1) for state in ['M', 'D', 'I']] + ['E']\n",
    "\n",
    "    trans_matrix = pd.DataFrame(0.0, columns=hmm_list, index=hmm_list)\n",
    "    emissions_matrix = pd.DataFrame(0.0, columns=alphabet, index=hmm_list)\n",
    "\n",
    "    populate_graph(alignment, alphabet, hmm_list, trans_matrix, emissions_matrix, seq_pos)\n",
    "\n",
    "    order = [\"S\", \"I0\"]\n",
    "    for i in range(1, len(alignment_star)+1):\n",
    "        order.append(f\"M{i}\")\n",
    "        order.append(f\"D{i}\")\n",
    "        order.append(f\"I{i}\")\n",
    "    order.append(\"E\")\n",
    "\n",
    "    trans_matrix = trans_matrix.reindex(index=order, columns=order)\n",
    "    emissions_matrix = emissions_matrix.reindex(index=order)\n",
    "    trans_matrix = trans_matrix.replace(0.0, 0)\n",
    "    emissions_matrix = emissions_matrix.replace(0.0, 0)\n",
    "\n",
    "    return trans_matrix, emissions_matrix\n",
    "\n",
    "transition, emission = profile_hmm(threshold_input, alphabet_input, alignment_input)\n",
    "\n",
    "with open('output.txt', 'w') as f:\n",
    "    f.write(transition.to_csv(sep='\\t', index=True, header=True))\n",
    "    f.write('--------\\n')\n",
    "    f.write(emission.to_csv(sep='\\t', index=True, header=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.358\n",
      "0.01\n",
      "['A', 'B', 'C', 'D', 'E']\n",
      "['A-A', 'ADA', 'ACA', 'A-C', '-EA', 'D-A']\n"
     ]
    }
   ],
   "source": [
    "def profile_hmm_with_pseudocounts_inputs(lines):\n",
    "    first_line = lines[0].strip().split()\n",
    "    threshold_input = float(first_line[0])\n",
    "    pseudocount_input = float(first_line[1])\n",
    "    \n",
    "    alphabet_input = lines[2].strip().split()\n",
    "    \n",
    "    alignment_input = [line.strip() for line in lines[4:] if line.strip()]\n",
    "    \n",
    "    return threshold_input, pseudocount_input, alphabet_input, alignment_input\n",
    "\n",
    "with open('06_PseudocountProfileHMM/inputs/sample.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "threshold_input, pseudocount_input, alphabet_input, alignment_input = profile_hmm_with_pseudocounts_inputs(lines)\n",
    "print(threshold_input)\n",
    "print(pseudocount_input)\n",
    "print(alphabet_input)\n",
    "print(alignment_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      S   I0        M1        D1   I1   M2   D2   I2    E\n",
      "S   0.0  0.0  0.833333  0.166667  0.0  0.0  0.0  0.0  0.0\n",
      "I0  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0\n",
      "M1  0.0  0.0  0.000000  0.000000  0.4  0.6  0.0  0.0  0.0\n",
      "D1  0.0  0.0  0.000000  0.000000  1.0  0.0  0.0  0.0  0.0\n",
      "I1  0.0  0.0  0.000000  0.000000  0.0  1.0  0.0  0.0  0.0\n",
      "M2  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  1.0\n",
      "D2  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0\n",
      "I2  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0\n",
      "E   0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0\n",
      "           A    B         C         D         E\n",
      "S   0.000000  0.0  0.000000  0.000000  0.000000\n",
      "I0  0.000000  0.0  0.000000  0.000000  0.000000\n",
      "M1  0.800000  0.0  0.000000  0.200000  0.000000\n",
      "D1  0.000000  0.0  0.000000  0.000000  0.000000\n",
      "I1  0.000000  0.0  0.333333  0.333333  0.333333\n",
      "M2  0.833333  0.0  0.166667  0.000000  0.000000\n",
      "D2  0.000000  0.0  0.000000  0.000000  0.000000\n",
      "I2  0.000000  0.0  0.000000  0.000000  0.000000\n",
      "E   0.000000  0.0  0.000000  0.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "def populate_graph(alignment, alphabet, hmm_list, trans_matrix, emissions_matrix, seq_pos, pseudocount):\n",
    "    transition_counts = {state: {target: 0 for target in hmm_list} for state in hmm_list}\n",
    "    emission_counts = {state: {letter: 0 for letter in alphabet} for state in hmm_list}\n",
    "\n",
    "    for sequence in alignment:\n",
    "        prev_state = 'S'\n",
    "        match_index = 0\n",
    "        for i in range(len(seq_pos)):\n",
    "            is_match = seq_pos[i][1]\n",
    "            if is_match:\n",
    "                match_index += 1\n",
    "                state = f'D{match_index}' if sequence[i] == '-' else f'M{match_index}'\n",
    "            else:\n",
    "                state = f'I{match_index}' if sequence[i] != '-' else None\n",
    "\n",
    "            if state:\n",
    "                if state in hmm_list:\n",
    "                    if state.startswith('M') or state.startswith('I'):\n",
    "                        if sequence[i] in alphabet:\n",
    "                            emission_counts[state][sequence[i]] += 1\n",
    "                    transition_counts[prev_state][state] += 1\n",
    "                    prev_state = state\n",
    "\n",
    "        transition_counts[prev_state]['E'] += 1\n",
    "\n",
    "    for state in hmm_list:\n",
    "        total_transitions = sum(transition_counts[state].values())\n",
    "        if total_transitions > 0:\n",
    "            for target in hmm_list:\n",
    "                trans_matrix.at[state, target] = transition_counts[state][target] / total_transitions\n",
    "    \n",
    "\n",
    "    for state in hmm_list:\n",
    "        total_emissions = sum(emission_counts[state].values())\n",
    "        if total_emissions > 0:\n",
    "            for letter in alphabet:\n",
    "                emissions_matrix.at[state, letter] = emission_counts[state][letter] / total_emissions\n",
    "\n",
    "\n",
    "    return trans_matrix, emissions_matrix\n",
    "\n",
    "\n",
    "def profile_hmm_with_pseudocounts(threshold: float, pseudocount: float, alphabet: List[str], alignment: List[str]):\n",
    "    seq_pos = []\n",
    "    for i in range(len(alignment[0])):\n",
    "        pos = [seq[i] for seq in alignment]\n",
    "        num_dels = sum(1 for letter in pos if letter == '-')\n",
    "        seq_pos.append((pos, num_dels / len(pos) < threshold))\n",
    "\n",
    "    alignment_star = [pos[0] for pos in seq_pos if pos[1]]\n",
    "\n",
    "    hmm_length = len(alignment_star)\n",
    "    hmm_list = ['S', 'I0'] + [f'{state}{i}' for i in range(1, hmm_length + 1) for state in ['M', 'D', 'I']] + ['E']\n",
    "\n",
    "    trans_matrix = pd.DataFrame(0.0, columns=hmm_list, index=hmm_list)\n",
    "    emissions_matrix = pd.DataFrame(0.0, columns=alphabet, index=hmm_list)\n",
    "\n",
    "    populate_graph(alignment, alphabet, hmm_list, trans_matrix, emissions_matrix, seq_pos, pseudocount)\n",
    "\n",
    "    order = [\"S\", \"I0\"]\n",
    "    for i in range(1, len(alignment_star)+1):\n",
    "        order.append(f\"M{i}\")\n",
    "        order.append(f\"D{i}\")\n",
    "        order.append(f\"I{i}\")\n",
    "    order.append(\"E\")\n",
    "\n",
    "    trans_matrix = trans_matrix.reindex(index=order, columns=order)\n",
    "    emissions_matrix = emissions_matrix.reindex(index=order)\n",
    "    trans_matrix = trans_matrix.replace(0.0, 0)\n",
    "    emissions_matrix = emissions_matrix.replace(0.0, 0)\n",
    "\n",
    "    return trans_matrix, emissions_matrix\n",
    "\n",
    "transition, emission = profile_hmm_with_pseudocounts(threshold_input, pseudocount_input, alphabet_input, alignment_input)\n",
    "\n",
    "# # with open('output.txt', 'w') as f:\n",
    "# #     f.write(transition.to_csv(sep='\\t', index=True, header=True))\n",
    "# #     f.write('--------\\n')\n",
    "# #     f.write(emission.to_csv(sep='\\t', index=True, header=True))\n",
    "\n",
    "print(transition)\n",
    "print(emission)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
